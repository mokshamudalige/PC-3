{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0EchQ2-mVeY",
        "outputId": "c4d60296-e28f-419b-c905-b9fee798be19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Dec  5 17:40:17 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   45C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile gaussian_blur_cuda.cu\n",
        "\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "#define WIDTH 1000\n",
        "#define HEIGHT 1000\n",
        "#define MAX_BLOCK_SIZE 32\n",
        "#define KERNEL_SIZE 3\n",
        "\n",
        "__constant__ float d_kernel[KERNEL_SIZE][KERNEL_SIZE];\n",
        "\n",
        "__global__ void gaussianBlurKernel(float *input, float *output, int width, int height) {\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "\n",
        "    if (row >= 1 && row < height - 1 && col >= 1 && col < width - 1) {\n",
        "        float sum = 0.0f;\n",
        "\n",
        "        for (int ki = -1; ki <= 1; ki++) {\n",
        "            for (int kj = -1; kj <= 1; kj++) {\n",
        "                int input_row = row + ki;\n",
        "                int input_col = col + kj;\n",
        "                int input_idx = input_row * width + input_col;\n",
        "\n",
        "                sum += input[input_idx] * d_kernel[ki + 1][kj + 1];\n",
        "            }\n",
        "        }\n",
        "\n",
        "        int output_idx = row * width + col;\n",
        "        output[output_idx] = sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void gaussianBlurKernelShared(float *input, float *output, int width, int height) {\n",
        "    __shared__ float shared_input[MAX_BLOCK_SIZE + 2][MAX_BLOCK_SIZE + 2];\n",
        "\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "\n",
        "    int local_col = threadIdx.x + 1;\n",
        "    int local_row = threadIdx.y + 1;\n",
        "\n",
        "    if (row < height && col < width) {\n",
        "        shared_input[local_row][local_col] = input[row * width + col];\n",
        "\n",
        "        if (threadIdx.x == 0 && col > 0) {\n",
        "            shared_input[local_row][0] = input[row * width + (col - 1)];\n",
        "        }\n",
        "        if (threadIdx.x == blockDim.x - 1 && col < width - 1) {\n",
        "            shared_input[local_row][local_col + 1] = input[row * width + (col + 1)];\n",
        "        }\n",
        "        if (threadIdx.y == 0 && row > 0) {\n",
        "            shared_input[0][local_col] = input[(row - 1) * width + col];\n",
        "        }\n",
        "        if (threadIdx.y == blockDim.y - 1 && row < height - 1) {\n",
        "            shared_input[local_row + 1][local_col] = input[(row + 1) * width + col];\n",
        "        }\n",
        "    }\n",
        "\n",
        "    __syncthreads();\n",
        "\n",
        "    if (row >= 1 && row < height - 1 && col >= 1 && col < width - 1) {\n",
        "        float sum = 0.0f;\n",
        "\n",
        "        for (int ki = -1; ki <= 1; ki++) {\n",
        "            for (int kj = -1; kj <= 1; kj++) {\n",
        "                sum += shared_input[local_row + ki][local_col + kj] * d_kernel[ki + 1][kj + 1];\n",
        "            }\n",
        "        }\n",
        "\n",
        "        output[row * width + col] = sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "#define CHECK_CUDA_ERROR(call) { \\\n",
        "    cudaError_t err = call; \\\n",
        "    if (err != cudaSuccess) { \\\n",
        "        fprintf(stderr, \"CUDA error in %s:%d: %s\\n\", __FILE__, __LINE__, \\\n",
        "                cudaGetErrorString(err)); \\\n",
        "        exit(EXIT_FAILURE); \\\n",
        "    } \\\n",
        "}\n",
        "\n",
        "void initializeImage(float *image) {\n",
        "    for (int i = 0; i < HEIGHT; i++) {\n",
        "        for (int j = 0; j < WIDTH; j++) {\n",
        "            int idx = i * WIDTH + j;\n",
        "            if (i > HEIGHT/4 && i < 3*HEIGHT/4 && j > WIDTH/4 && j < 3*WIDTH/4) {\n",
        "                image[idx] = 100.0f;\n",
        "            } else {\n",
        "                image[idx] = 10.0f;\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "void printImageSample(float *image, int sample_size) {\n",
        "    printf(\"Sample output (%dx%d from center):\\n\", sample_size, sample_size);\n",
        "    int start_i = HEIGHT/2 - sample_size/2;\n",
        "    int start_j = WIDTH/2 - sample_size/2;\n",
        "\n",
        "    for (int i = start_i; i < start_i + sample_size; i++) {\n",
        "        for (int j = start_j; j < start_j + sample_size; j++) {\n",
        "            printf(\"%6.2f \", image[i * WIDTH + j]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "}\n",
        "\n",
        "int main(int argc, char *argv[]) {\n",
        "    int block_size = 16;\n",
        "    int use_shared_memory = 0;\n",
        "\n",
        "    if (argc > 1) {\n",
        "        block_size = atoi(argv[1]);\n",
        "        if (block_size < 1 || block_size > MAX_BLOCK_SIZE) {\n",
        "            printf(\"Invalid block size. Using default: 16\\n\");\n",
        "            block_size = 16;\n",
        "        }\n",
        "    }\n",
        "    if (argc > 2) {\n",
        "        use_shared_memory = atoi(argv[2]);\n",
        "    }\n",
        "\n",
        "    printf(\"=== Gaussian Blur - CUDA Implementation ===\\n\");\n",
        "    printf(\"Image Size: %dx%d\\n\", WIDTH, HEIGHT);\n",
        "    printf(\"Block Size: %dx%d\\n\", block_size, block_size);\n",
        "    printf(\"Kernel Version: %s\\n\\n\", use_shared_memory ? \"Shared Memory\" : \"Basic\");\n",
        "\n",
        "    cudaDeviceProp prop;\n",
        "    CHECK_CUDA_ERROR(cudaGetDeviceProperties(&prop, 0));\n",
        "    printf(\"GPU Device: %s\\n\", prop.name);\n",
        "    printf(\"Compute Capability: %d.%d\\n\", prop.major, prop.minor);\n",
        "    printf(\"Max Threads per Block: %d\\n\\n\", prop.maxThreadsPerBlock);\n",
        "\n",
        "    size_t image_size = WIDTH * HEIGHT * sizeof(float);\n",
        "    float *h_input = (float *)malloc(image_size);\n",
        "    float *h_output = (float *)malloc(image_size);\n",
        "\n",
        "    if (h_input == NULL || h_output == NULL) {\n",
        "        printf(\"Host memory allocation failed!\\n\");\n",
        "        return 1;\n",
        "    }\n",
        "\n",
        "    initializeImage(h_input);\n",
        "\n",
        "    for (int i = 0; i < WIDTH * HEIGHT; i++) {\n",
        "        h_output[i] = 0.0f;\n",
        "    }\n",
        "\n",
        "    float *d_input, *d_output;\n",
        "    CHECK_CUDA_ERROR(cudaMalloc(&d_input, image_size));\n",
        "    CHECK_CUDA_ERROR(cudaMalloc(&d_output, image_size));\n",
        "\n",
        "    float h_kernel[KERNEL_SIZE][KERNEL_SIZE] = {\n",
        "        {1/16.0f, 2/16.0f, 1/16.0f},\n",
        "        {2/16.0f, 4/16.0f, 2/16.0f},\n",
        "        {1/16.0f, 2/16.0f, 1/16.0f}\n",
        "    };\n",
        "    CHECK_CUDA_ERROR(cudaMemcpyToSymbol(d_kernel, h_kernel,\n",
        "                     KERNEL_SIZE * KERNEL_SIZE * sizeof(float)));\n",
        "\n",
        "    CHECK_CUDA_ERROR(cudaMemcpy(d_input, h_input, image_size, cudaMemcpyHostToDevice));\n",
        "    CHECK_CUDA_ERROR(cudaMemcpy(d_output, h_output, image_size, cudaMemcpyHostToDevice));\n",
        "\n",
        "    dim3 block_dim(block_size, block_size);\n",
        "    dim3 grid_dim((WIDTH + block_size - 1) / block_size,\n",
        "                  (HEIGHT + block_size - 1) / block_size);\n",
        "\n",
        "    printf(\"Grid Dimensions: %dx%d blocks\\n\", grid_dim.x, grid_dim.y);\n",
        "    printf(\"Total Threads: %d\\n\\n\", grid_dim.x * grid_dim.y * block_size * block_size);\n",
        "\n",
        "    cudaEvent_t start, stop;\n",
        "    CHECK_CUDA_ERROR(cudaEventCreate(&start));\n",
        "    CHECK_CUDA_ERROR(cudaEventCreate(&stop));\n",
        "\n",
        "    CHECK_CUDA_ERROR(cudaEventRecord(start));\n",
        "\n",
        "    if (use_shared_memory) {\n",
        "        gaussianBlurKernelShared<<<grid_dim, block_dim>>>(d_input, d_output, WIDTH, HEIGHT);\n",
        "    } else {\n",
        "        gaussianBlurKernel<<<grid_dim, block_dim>>>(d_input, d_output, WIDTH, HEIGHT);\n",
        "    }\n",
        "\n",
        "    CHECK_CUDA_ERROR(cudaEventRecord(stop));\n",
        "    CHECK_CUDA_ERROR(cudaEventSynchronize(stop));\n",
        "    CHECK_CUDA_ERROR(cudaGetLastError());\n",
        "\n",
        "    float milliseconds = 0;\n",
        "    CHECK_CUDA_ERROR(cudaEventElapsedTime(&milliseconds, start, stop));\n",
        "    float execution_time = milliseconds / 1000.0f;\n",
        "\n",
        "    CHECK_CUDA_ERROR(cudaMemcpy(h_output, d_output, image_size, cudaMemcpyDeviceToHost));\n",
        "\n",
        "    printf(\"Execution Time: %.6f seconds (%.3f ms)\\n\\n\", execution_time, milliseconds);\n",
        "\n",
        "    printImageSample(h_output, 5);\n",
        "\n",
        "    printf(\"\\n=== Performance Metrics ===\\n\");\n",
        "    printf(\"Total pixels processed: %d\\n\", WIDTH * HEIGHT);\n",
        "    printf(\"Pixels per second: %.2f million\\n\", (WIDTH * HEIGHT) / (execution_time * 1e6));\n",
        "    printf(\"GPU Throughput: %.2f GFLOPS\\n\",\n",
        "           (WIDTH * HEIGHT * 9 * 2) / (execution_time * 1e9));\n",
        "\n",
        "    CHECK_CUDA_ERROR(cudaEventDestroy(start));\n",
        "    CHECK_CUDA_ERROR(cudaEventDestroy(stop));\n",
        "    CHECK_CUDA_ERROR(cudaFree(d_input));\n",
        "    CHECK_CUDA_ERROR(cudaFree(d_output));\n",
        "    free(h_input);\n",
        "    free(h_output);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UbunEtJKmc_Z",
        "outputId": "9538a7c0-d990-4f4e-f8d4-48097538054e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing gaussian_blur_cuda.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 -O3 gaussian_blur_cuda.cu -o gaussian_blur_cuda"
      ],
      "metadata": {
        "id": "3jXCU5tvmian"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8x8 Basic\n",
        "!./gaussian_blur_cuda 8 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yW2LUtSOmoKx",
        "outputId": "8cf7fff5-859c-461a-ddda-6d97f3bbec0e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Gaussian Blur - CUDA Implementation ===\n",
            "Image Size: 1000x1000\n",
            "Block Size: 8x8\n",
            "Kernel Version: Basic\n",
            "\n",
            "GPU Device: Tesla T4\n",
            "Compute Capability: 7.5\n",
            "Max Threads per Block: 1024\n",
            "\n",
            "Grid Dimensions: 125x125 blocks\n",
            "Total Threads: 1000000\n",
            "\n",
            "Execution Time: 0.000149 seconds (0.149 ms)\n",
            "\n",
            "Sample output (5x5 from center):\n",
            "100.00 100.00 100.00 100.00 100.00 \n",
            "100.00 100.00 100.00 100.00 100.00 \n",
            "100.00 100.00 100.00 100.00 100.00 \n",
            "100.00 100.00 100.00 100.00 100.00 \n",
            "100.00 100.00 100.00 100.00 100.00 \n",
            "\n",
            "=== Performance Metrics ===\n",
            "Total pixels processed: 1000000\n",
            "Pixels per second: 6732.01 million\n",
            "GPU Throughput: 121.18 GFLOPS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 16x16 Basic\n",
        "!./gaussian_blur_cuda 16 0\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7BqI35DmwfB",
        "outputId": "e1292a8f-fb12-442a-8730-cc5df6dcc276"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Gaussian Blur - CUDA Implementation ===\n",
            "Image Size: 1000x1000\n",
            "Block Size: 16x16\n",
            "Kernel Version: Basic\n",
            "\n",
            "GPU Device: Tesla T4\n",
            "Compute Capability: 7.5\n",
            "Max Threads per Block: 1024\n",
            "\n",
            "Grid Dimensions: 63x63 blocks\n",
            "Total Threads: 1016064\n",
            "\n",
            "Execution Time: 0.000096 seconds (0.096 ms)\n",
            "\n",
            "Sample output (5x5 from center):\n",
            "100.00 100.00 100.00 100.00 100.00 \n",
            "100.00 100.00 100.00 100.00 100.00 \n",
            "100.00 100.00 100.00 100.00 100.00 \n",
            "100.00 100.00 100.00 100.00 100.00 \n",
            "100.00 100.00 100.00 100.00 100.00 \n",
            "\n",
            "=== Performance Metrics ===\n",
            "Total pixels processed: 1000000\n",
            "Pixels per second: 10430.57 million\n",
            "GPU Throughput: 187.75 GFLOPS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 32x32 Basic\n",
        "!./gaussian_blur_cuda 32 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2P3qlXvm2kD",
        "outputId": "8f7f18bb-661c-44e7-e032-5b78612f6e43"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Gaussian Blur - CUDA Implementation ===\n",
            "Image Size: 1000x1000\n",
            "Block Size: 32x32\n",
            "Kernel Version: Basic\n",
            "\n",
            "GPU Device: Tesla T4\n",
            "Compute Capability: 7.5\n",
            "Max Threads per Block: 1024\n",
            "\n",
            "Grid Dimensions: 32x32 blocks\n",
            "Total Threads: 1048576\n",
            "\n",
            "Execution Time: 0.000075 seconds (0.075 ms)\n",
            "\n",
            "Sample output (5x5 from center):\n",
            "100.00 100.00 100.00 100.00 100.00 \n",
            "100.00 100.00 100.00 100.00 100.00 \n",
            "100.00 100.00 100.00 100.00 100.00 \n",
            "100.00 100.00 100.00 100.00 100.00 \n",
            "100.00 100.00 100.00 100.00 100.00 \n",
            "\n",
            "=== Performance Metrics ===\n",
            "Total pixels processed: 1000000\n",
            "Pixels per second: 13269.64 million\n",
            "GPU Throughput: 238.85 GFLOPS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 8x8 Shared Memory\n",
        "!./gaussian_blur_cuda 8 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pjNHahOm5DU",
        "outputId": "52ca7370-bc63-47ff-b38b-695038f34c4b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Gaussian Blur - CUDA Implementation ===\n",
            "Image Size: 1000x1000\n",
            "Block Size: 8x8\n",
            "Kernel Version: Shared Memory\n",
            "\n",
            "GPU Device: Tesla T4\n",
            "Compute Capability: 7.5\n",
            "Max Threads per Block: 1024\n",
            "\n",
            "Grid Dimensions: 125x125 blocks\n",
            "Total Threads: 1000000\n",
            "\n",
            "Execution Time: 0.000179 seconds (0.179 ms)\n",
            "\n",
            "Sample output (5x5 from center):\n",
            "100.00 100.00 100.00 100.00 100.00 \n",
            "100.00 100.00 100.00 100.00 100.00 \n",
            "100.00 100.00 100.00 100.00 100.00 \n",
            "100.00 100.00 100.00 100.00 100.00 \n",
            "100.00 100.00 100.00 100.00 100.00 \n",
            "\n",
            "=== Performance Metrics ===\n",
            "Total pixels processed: 1000000\n",
            "Pixels per second: 5592.34 million\n",
            "GPU Throughput: 100.66 GFLOPS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 16x16 Shared Memory\n",
        "!./gaussian_blur_cuda 16 1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xIQkcDonF1d",
        "outputId": "ed9b8deb-ca16-440f-ac64-0737505abc66"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Gaussian Blur - CUDA Implementation ===\n",
            "Image Size: 1000x1000\n",
            "Block Size: 16x16\n",
            "Kernel Version: Shared Memory\n",
            "\n",
            "GPU Device: Tesla T4\n",
            "Compute Capability: 7.5\n",
            "Max Threads per Block: 1024\n",
            "\n",
            "Grid Dimensions: 63x63 blocks\n",
            "Total Threads: 1016064\n",
            "\n",
            "Execution Time: 0.000114 seconds (0.114 ms)\n",
            "\n",
            "Sample output (5x5 from center):\n",
            "100.00 100.00 100.00 100.00 100.00 \n",
            "100.00 100.00 100.00 100.00 100.00 \n",
            "100.00 100.00 100.00 100.00 100.00 \n",
            "100.00 100.00 100.00 100.00 100.00 \n",
            "100.00 100.00 100.00 100.00 100.00 \n",
            "\n",
            "=== Performance Metrics ===\n",
            "Total pixels processed: 1000000\n",
            "Pixels per second: 8810.26 million\n",
            "GPU Throughput: 158.58 GFLOPS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 32x32 Shared Memory\n",
        "!./gaussian_blur_cuda 32 1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mlsIqbyrnKqi",
        "outputId": "b97e880a-a8c7-4dc1-cd0a-f6e5e9a3a04b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Gaussian Blur - CUDA Implementation ===\n",
            "Image Size: 1000x1000\n",
            "Block Size: 32x32\n",
            "Kernel Version: Shared Memory\n",
            "\n",
            "GPU Device: Tesla T4\n",
            "Compute Capability: 7.5\n",
            "Max Threads per Block: 1024\n",
            "\n",
            "Grid Dimensions: 32x32 blocks\n",
            "Total Threads: 1048576\n",
            "\n",
            "Execution Time: 0.000108 seconds (0.108 ms)\n",
            "\n",
            "Sample output (5x5 from center):\n",
            "100.00 100.00 100.00 100.00 100.00 \n",
            "100.00 100.00 100.00 100.00 100.00 \n",
            "100.00 100.00 100.00 100.00 100.00 \n",
            "100.00 100.00 100.00 100.00 100.00 \n",
            "100.00 100.00 100.00 100.00 100.00 \n",
            "\n",
            "=== Performance Metrics ===\n",
            "Total pixels processed: 1000000\n",
            "Pixels per second: 9221.01 million\n",
            "GPU Throughput: 165.98 GFLOPS\n"
          ]
        }
      ]
    }
  ]
}